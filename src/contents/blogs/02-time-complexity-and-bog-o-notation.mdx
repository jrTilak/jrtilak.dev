---
title: Time Complexity and Big O Notation [02]
publishedAt: Sun Nov 24 2024 18:34:21 GMT+0545 (Nepal Time)
image: "/images/blogs/02-time-complexity-and-big-o-notation/thumbnail.png"
tags: ["dsa-series"]
metaTags: ["algorithms",
      "data structures",
      "time complexity",
      "big o notation",
      "c++",
      "programming",
      "computer science",
      "algorithm analysis",
      "coding",
      "performance",
      "optimization",
      "space complexity",
      "competitive programming",
      "technical interview",
      "dsa"]
summary: "🚀 Master Time Complexity & Big O Notation! Deep dive into algorithm analysis with practical C++ examples. From basics to advanced optimization. Perfect for coding interviews!"
---

## Introduction

Understanding time complexity and Big O notation is crucial for writing efficient code and becoming a better programmer. In this blog post, we'll dive deep into these concepts, learn how to analyze algorithms, and see practical examples using C++.

## What is Time Complexity?

Time complexity is a way to measure how an algorithm's runtime grows as the input size increases. Or simply, `Time complexity is the study of efficiency of algorithm.` Rather than measuring actual time in seconds (which varies based on hardware), we count the number of elementary operations performed by the algorithm.

Consider these two C++ functions that find the sum of numbers from 1 to n:

```cpp
// Method 1: Using a loop
int sumUsingLoop(int n) {
    int sum = 0;
    for (int i = 1; i <= n; i++) {
        sum += i;
    }
    return sum;
}

// Method 2: Using mathematical formula
int sumUsingFormula(int n) {
    return (n * (n + 1)) / 2;
}
```

While both functions give the same result, they have very different time complexities. The first function runs n times, while the second performs just three operations regardless of n.

## Understanding Big O Notation

Big O notation describes the upper bound of the growth rate of an algorithm. It's written as `O(f(n))`, where `f(n)` represents the growth rate function.

Common Big O complexities (from fastest to slowest):
- O(1) - Constant time
- O(log n) - Logarithmic time
- O(n) - Linear time
- O(n log n) - Linearithmic time
- O(n²) - Quadratic time
- O(2ⁿ) - Exponential time

### O(1) - Constant Time
Operations that don't depend on input size:

```cpp
int getFirstElement(vector<int>& arr) {
    if (arr.empty()) return -1;
    return arr[0];
}
```

### O(n) - Linear Time
Operations that scale linearly with input:

```cpp
bool linearSearch(vector<int>& arr, int target) {
    for (int num : arr) {
        if (num == target) return true;
    }
    return false;
}
```

### O(log n) - Logarithmic Time
Operations that reduce the problem size by half each time:

```cpp
int binarySearch(vector<int>& arr, int target) {
    int left = 0;
    int right = arr.size() - 1;
    
    while (left <= right) {
        int mid = left + (right - left) / 2;
        if (arr[mid] == target) return mid;
        if (arr[mid] < target) left = mid + 1;
        else right = mid - 1;
    }
    return -1;
}
```

### O(n²) - Quadratic Time
Nested iterations over the input:

```cpp
void bubbleSort(vector<int>& arr) {
    int n = arr.size();
    for (int i = 0; i < n - 1; i++) {
        for (int j = 0; j < n - i - 1; j++) {
            if (arr[j] > arr[j + 1]) {
                swap(arr[j], arr[j + 1]);
            }
        }
    }
}
```

  ![Complexity Chart](/images/blogs/02-time-complexity-and-big-o-notation/complexity-chart.png)

## How to Calculate Time Complexity

Follow these steps to analyze an algorithm:

1. Count the operations in the innermost part of your code
2. Multiply by the number of times each loop runs
3. Keep only the highest-order term
4. Drop constants and coefficients

### Example Analysis

Let's analyze this function:

```cpp
void findPairs(vector<int>& arr) {
    int n = arr.size();
    
    // Print all pairs
    for (int i = 0; i < n; i++) {           // Runs n times
        for (int j = i + 1; j < n; j++) {   // Runs (n-i) times
            cout << arr[i] << "," << arr[j] << endl;
        }
    }
}
```

Analysis:
1. Inner loop runs (n-i) times for each i
2. Total operations: Σ(n-i) from i=0 to n-1
3. This sum equals n(n-1)/2
4. Simplifying and keeping highest order: O(n²)

## Common Pitfalls

### 1. Adding vs. Multiplying Complexities

```cpp
// O(n + m) - Two separate loops
void process(vector<int>& arr1, vector<int>& arr2) {
    for (int num : arr1) { /* O(n) */ }
    for (int num : arr2) { /* O(m) */ }
}

// O(n * m) - Nested loops
void process2(vector<int>& arr1, vector<int>& arr2) {
    for (int num1 : arr1) {      // O(n)
        for (int num2 : arr2) {  // O(m)
            // Process pair
        }
    }
}
```

### 2. Hidden Loops

Remember that some C++ operations have their own complexities:
- `vector.push_back()` - Usually O(1), but can be O(n) when resizing
- `unordered_map.find()` - O(1) average, O(n) worst case
- `sort()` - O(n log n)

## Best Practices for Writing Efficient Code

1. Choose appropriate data structures
   - Use `unordered_map` instead of `map` when order doesn't matter
   - Use `vector` instead of `list` for sequential access

2. Avoid unnecessary nested loops
   - Use hash tables for lookup operations
   - Consider preprocessing data when possible

3. Look for mathematical solutions
   - Like our initial sum example, mathematical formulas often provide O(1) solutions

## Conclusion

Understanding time complexity and Big O notation is essential for writing efficient code. When designing algorithms, always consider:
- The size of your input
- The worst-case scenario
- The trade-off between time and space complexity
- Whether a more efficient solution exists

Remember that the fastest algorithm isn't always the best choice - consider factors like code readability, maintenance, and the actual size of your input data.

## Practice Problems

To solidify your understanding, try analyzing the time complexity of these functions:

```cpp
// Problem 1
int mystery1(int n) {
    int result = 0;
    for (int i = 1; i <= n; i *= 2) {
        result += i;
    }
    return result;
}

// Problem 2
void mystery2(vector<int>& arr) {
    int n = arr.size();
    for (int i = 0; i < n; i++) {
        for (int j = i; j < n; j++) {
            for (int k = i; k <= j; k++) {
                cout << arr[k] << " ";
            }
            cout << endl;
        }
    }
}
```

(Solutions: mystery1 is O(log n), mystery2 is O(n³))

Remember: The best way to understand time complexity is through practice. Try analyzing different algorithms and writing your own solutions with efficiency in mind.